---
layout: post
title: python网络爬虫
date: 2021-05-09
Author: karinlee
tags: [python]
toc: true
---

通过编写程序来获取到互联网上的资源



## 开始使用

### 使用urllib.request将网页的源代码保存到本地html文件中



```python
from urllib.request import urlopen
# 注意utf-8编码解码
url = "http://www.baidu.com"
resp = urlopen(url)
# print(resp.read().decode('utf-8'))
with open('mybaidu.html',mode='w',encoding='utf-8') as f:
    f.write(resp.read().decode('utf-8'))  # 读取到网页的页面源代码
print("over!")
```



### WEB请求过程剖析

1.服务器渲染：在服务器那边直接把数据和html整合在一起，统一返回给浏览器
在页面源代码中能看到数据

2.客户端渲染：第一次请求只要一个html骨架，第二次请求拿到数据，进行数据展示，
在页面源代码中，看不到数据。

3.熟练使用浏览器抓包工具  使用chrome浏览器 F12 NetWork



### HTTP协议
**请求：** 
1 请求行 -> 请求方式（get/post) 请求url地址 协议 
2 请求头 -> 放一些服务器要使用的附加信息 
3 
4 请求体 -> 一般放一些请求参数 

**响应：** 
1 状态行 -> 协议 状态码 
2 响应头 -> 放一些客户端要使用的一些附加信息 
3 
4 响应体 -> 服务器返回的真正客户端要用的内容（HTML,json等）



### requests入门



**在地址栏上请求的链接一定采取GET请求方式。**  



**网页地址栏的链接中，问号前面的是url，问号后面的是参数。**



**GET请求方式一般Headers最下面是 Query String Parameters， POST请求方式Headers最下面是Form Data。**



- 示例：使用搜狗搜索搜索“周杰伦”，并返回搜索后的结果网页源代码。（GET请求）

```python
import requests  
      
query = "周杰伦"  
      
url =  f"https://www.sogou.com/web?query={query}"  
      
headers = {  
                "User-Agent":"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36"  
    }  
resp = requests.get(url,headers=headers)  
print(resp)  
print(resp.text)# 返回页面源代码
```
- 使用百度翻译翻译“dog”。

```python
import requests

url = 'https://fanyi.baidu.com/sug'

s = "dog"
dat = {
    "kw": s
}

#发送post请求,发送的数据必须放在字典中，通过data参数进行传递

resp = requests.post(url=url,data=dat)
print(resp.json())  # 将服务器返回的内容直接处理成json() => dict
```

- 查找豆瓣热门喜剧片列表

```python
# 网页地址栏的链接中，问号前面的是url，问号后面的是参数
# GET请求方式一般Headers最下面是 Query String Parameters， POST请求方式Headers最下面是Form Data

import requests
baseurl = 'https://movie.douban.com/j/chart/top_list?type=24&interval_id=100%3A90&action=&start=0&limit=20'
# Headers里面的链接太长了，通过下面方式重新构造。先保留问号前的url，问号后面的参数构造成字典。
url = 'https://movie.douban.com/j/chart/top_list'
headers = {
            "User-Agent":"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36"
}

# 重新封装参数
param = {
    "type": "24",
    "interval_id": "100:90",
    "action":"",
    "start": "0",
    "limit": "20",

}

resp = requests.get(url=url,params=param,headers=headers)
# print(resp.request.url)
print(resp.request.headers)
print(resp.json())
```